{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#== Parameters =======================================================================\n",
    "BLUR = 21\n",
    "CANNY_THRESH_1 = 10\n",
    "CANNY_THRESH_2 = 200\n",
    "MASK_DILATE_ITER = 10\n",
    "MASK_ERODE_ITER = 10\n",
    "MASK_COLOR = (0.0,0.0,1.0) # In BGR format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#== Processing ======================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- Read image -----------------------------------------------------------------------\n",
    "img = cv2.imread('../ikea_scraper/img_users/Imagen 2.jpeg')\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- Edge detection -------------------------------------------------------------------\n",
    "edges = cv2.Canny(gray, CANNY_THRESH_1, CANNY_THRESH_2)\n",
    "edges = cv2.dilate(edges, None)\n",
    "edges = cv2.erode(edges, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- Find contours in edges, sort by area ---------------------------------------------\n",
    "contour_info = []\n",
    "# _, contours, _ = cv2.findContours(edges, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "# Previously, for a previous version of cv2, this line was: \n",
    "contours, _ = cv2.findContours(edges, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "# Thanks to notes from commenters, I've updated the code but left this note\n",
    "for c in contours:\n",
    "    contour_info.append((\n",
    "        c,\n",
    "        cv2.isContourConvex(c),\n",
    "        cv2.contourArea(c),\n",
    "    ))\n",
    "contour_info = sorted(contour_info, key=lambda c: c[2], reverse=True)\n",
    "max_contour = contour_info[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#-- Create empty mask, draw filled polygon on it corresponding to largest contour ----\n",
    "# Mask is black, polygon is white\n",
    "mask = np.zeros(edges.shape)\n",
    "cv2.fillConvexPoly(mask, max_contour[0], (255))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- Smooth mask, then blur it --------------------------------------------------------\n",
    "mask = cv2.dilate(mask, None, iterations=MASK_DILATE_ITER)\n",
    "mask = cv2.erode(mask, None, iterations=MASK_ERODE_ITER)\n",
    "mask = cv2.GaussianBlur(mask, (BLUR, BLUR), 0)\n",
    "mask_stack = np.dstack([mask]*3)    # Create 3-channel alpha mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- Blend masked img into MASK_COLOR background --------------------------------------\n",
    "mask_stack  = mask_stack.astype('float32') / 255.0          # Use float matrices, \n",
    "img         = img.astype('float32') / 255.0                 #  for easy blending\n",
    "\n",
    "masked = (mask_stack * img) + ((1-mask_stack) * MASK_COLOR) # Blend\n",
    "masked = (masked * 255).astype('uint8')                     # Convert back to 8-bit \n",
    "\n",
    "cv2.imshow('img', masked)                                   # Display\n",
    "cv2.waitKey()\n",
    "\n",
    "#cv2.imwrite('C:/Temp/person-masked.jpg', masked)           # Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### TO PUT A TRANSPARENT BACKGROUND #####\n",
    "\n",
    "# split image into channels\n",
    "c_red, c_green, c_blue = cv2.split(img)\n",
    "\n",
    "# merge with mask got on one of a previous steps\n",
    "img_a = cv2.merge((c_red, c_green, c_blue, mask.astype('float32') / 255.0))\n",
    "\n",
    "# show on screen (optional in jupiter)\n",
    "%matplotlib inline\n",
    "plt.imshow(img_a)\n",
    "plt.show()\n",
    "\n",
    "# save to disk\n",
    "cv2.imwrite('girl_1.png', img_a*255)\n",
    "\n",
    "# or the same using plt\n",
    "plt.imsave('girl_2.png', img_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comvis_env",
   "language": "python",
   "name": "comvis_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
